{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxaKka221EmvDaRrIh6SqD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benbaz-2/comp551/blob/main/A4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "clxTfQb76DY9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Voymw_0qqouS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import csr_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data processing"
      ],
      "metadata": {
        "id": "WmhqzZE46J4e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_parquet(\"hf://datasets/google-research-datasets/go_emotions/raw/train-00000-of-00001.parquet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaWi9At75-ND",
        "outputId": "2cae74a1-4423-4e19-8691-4f5cb67ee3ac"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = df.columns[9:]"
      ],
      "metadata": {
        "id": "Lf8JG1Ijq-2J"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df[df[labels].sum(axis=1) == 1]"
      ],
      "metadata": {
        "id": "dXymz1OHrtpn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comments = df1['text'].tolist()\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X = vectorizer.fit_transform(comments)\n",
        "y = df1[labels].values\n",
        "y = np.argmax(y, axis=1)"
      ],
      "metadata": {
        "id": "NJkaAzxOt2ek"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naive Bayes Implementation"
      ],
      "metadata": {
        "id": "wRtvmqCl6Ppe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note X must be a sparse matrix. This is because the session crashes otherwise\n",
        "# y is integer encoded not one hot encoded\n",
        "\n",
        "class NaiveBayes:\n",
        "    def __init__(self):\n",
        "        self.px = None\n",
        "        self.py = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Shape of X is (N, L) where L is the length of the embedding vectors, X is a sparse matrix\n",
        "        # Shape of y is (N,) where N is sample size\n",
        "\n",
        "        self.X = X    # Bag of words representation\n",
        "        self.y = y    # Integer labeled\n",
        "        n = X.shape[0]\n",
        "        C = len(np.unique(y))\n",
        "\n",
        "        # Compute class priors (py)\n",
        "        for c in range(C):\n",
        "            self.py = np.bincount(y)[c] / n\n",
        "\n",
        "        # Initialize px as a list to store likelihoods\n",
        "        self.px = []\n",
        "\n",
        "        for c in range(C):\n",
        "            # Select samples where the class is c\n",
        "            y_c = (y == c)  # Binary mask for samples with class c\n",
        "            X_c = X[y_c == 1]  # Extract samples where class is c\n",
        "\n",
        "            # Compute the likelihood P(x_i | y_c) for each feature\n",
        "            px_c = (X_c.sum(axis=0) + 1) / (y_c.sum() + X.shape[1])\n",
        "            px_c = np.asarray(px_c).ravel()  # Ensure it's a dense 1D array\n",
        "\n",
        "            self.px.append(px_c)  # Add the likelihoods for class c\n",
        "\n",
        "        # Convert px to numpy array of shape (C, L)\n",
        "        self.px = np.array(self.px)\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Compute the log of the posterior probabilities for each class\n",
        "        log_py = np.log(self.py)  # Log of class priors\n",
        "        log_px = np.log(self.px)  # Log of feature likelihoods\n",
        "\n",
        "        # Compute log-posterior for each class (N samples, C classes)\n",
        "        log_posterior = X.dot(log_px.T) + log_py  # `X` remains sparse\n",
        "\n",
        "        # Return the class with the highest posterior probability for each sample\n",
        "        return np.argmax(log_posterior, axis=1)\n",
        "\n",
        "    def evaluate_acc(self, Y, Yh):\n",
        "        return np.mean(Y == Yh)\n"
      ],
      "metadata": {
        "id": "LDiUORQu3jw2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NaiveBayes()\n",
        "model.fit(X, y)\n",
        "Yh = model.predict(X)\n",
        "model.evaluate_acc(y, Yh)"
      ],
      "metadata": {
        "id": "BOX1bmpO6UPl",
        "outputId": "b8cf3b94-d43a-4da9-e921-58b638633224",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.41989873123035737"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_counts = np.bincount(y)\n",
        "print(\"Class counts:\", class_counts)\n"
      ],
      "metadata": {
        "id": "HJqssRKIE6iD",
        "outputId": "047176f4-bb85-4b81-eaba-c2e435570164",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class counts: [10531  6130  5202  8342 11259  3523  4938  5885  2147  4706  7686  2914\n",
            "  1433  3020  1778  7075   351  4329  4957   796  4519   690  4714   788\n",
            "  1510  3827  3472 55298]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_accuracy = np.max(np.sum(y, axis=0)) / y.shape[0]\n",
        "print(f\"Baseline Accuracy: {baseline_accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "99wlM_atGirC",
        "outputId": "233a3375-be30-4273-f76b-342c8b93ba21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Accuracy: 15.46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=40, random_state=42, n_jobs=-1, verbose=1, max_depth=40)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "7Nks1wTu6vPb",
        "outputId": "93e43b7f-e40c-4270-e805-9d8818b12e9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  1.5min finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.37940868350599466\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.23      0.34      2121\n",
            "           1       0.56      0.22      0.32      1200\n",
            "           2       0.39      0.01      0.02      1009\n",
            "           3       0.27      0.00      0.01      1663\n",
            "           4       0.63      0.03      0.06      2366\n",
            "           5       0.42      0.01      0.01       708\n",
            "           6       0.63      0.03      0.06       964\n",
            "           7       0.80      0.05      0.09      1175\n",
            "           8       0.40      0.11      0.17       416\n",
            "           9       0.46      0.01      0.01       957\n",
            "          10       0.25      0.00      0.01      1542\n",
            "          11       0.77      0.06      0.11       584\n",
            "          12       0.75      0.01      0.02       299\n",
            "          13       0.71      0.06      0.11       572\n",
            "          14       0.78      0.02      0.04       372\n",
            "          15       0.85      0.70      0.77      1396\n",
            "          16       0.00      0.00      0.00        76\n",
            "          17       0.44      0.06      0.11       850\n",
            "          18       0.65      0.12      0.20      1037\n",
            "          19       0.00      0.00      0.00       150\n",
            "          20       0.54      0.05      0.09       884\n",
            "          21       0.00      0.00      0.00       128\n",
            "          22       0.00      0.00      0.00       943\n",
            "          23       0.00      0.00      0.00       149\n",
            "          24       0.38      0.02      0.03       310\n",
            "          25       0.71      0.03      0.05       797\n",
            "          26       0.41      0.02      0.03       711\n",
            "          27       0.35      0.98      0.51     10985\n",
            "\n",
            "    accuracy                           0.38     34364\n",
            "   macro avg       0.46      0.10      0.11     34364\n",
            "weighted avg       0.47      0.38      0.26     34364\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Done  40 out of  40 | elapsed:    0.4s finished\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred = rf_classifier.predict(X_train)\n",
        "print(\"Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_train, y_train_pred))"
      ],
      "metadata": {
        "id": "2cDXp10GC_If",
        "outputId": "5186b6ae-a28c-4307-8203-959526051a29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  40 out of  40 | elapsed:    1.0s finished\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.40796327552089395\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.27      0.41      8410\n",
            "           1       0.75      0.33      0.46      4930\n",
            "           2       0.87      0.03      0.06      4193\n",
            "           3       0.80      0.01      0.02      6679\n",
            "           4       0.81      0.04      0.07      8893\n",
            "           5       0.78      0.02      0.03      2815\n",
            "           6       0.92      0.05      0.09      3974\n",
            "           7       0.92      0.06      0.11      4710\n",
            "           8       0.68      0.19      0.29      1731\n",
            "           9       0.82      0.01      0.02      3749\n",
            "          10       0.85      0.01      0.02      6144\n",
            "          11       0.93      0.07      0.13      2330\n",
            "          12       0.90      0.02      0.04      1134\n",
            "          13       0.89      0.06      0.12      2448\n",
            "          14       0.95      0.04      0.08      1406\n",
            "          15       0.90      0.75      0.82      5679\n",
            "          16       0.00      0.00      0.00       275\n",
            "          17       0.79      0.13      0.22      3479\n",
            "          18       0.83      0.22      0.35      3920\n",
            "          19       0.00      0.00      0.00       646\n",
            "          20       0.87      0.11      0.19      3635\n",
            "          21       1.00      0.00      0.00       562\n",
            "          22       0.83      0.01      0.01      3771\n",
            "          23       1.00      0.01      0.02       639\n",
            "          24       0.85      0.05      0.10      1200\n",
            "          25       0.93      0.04      0.08      3030\n",
            "          26       0.83      0.05      0.09      2761\n",
            "          27       0.36      0.99      0.53     44313\n",
            "\n",
            "    accuracy                           0.41    137456\n",
            "   macro avg       0.78      0.13      0.16    137456\n",
            "weighted avg       0.68      0.41      0.30    137456\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train\n",
        "np.argmax(y_train, axis=1)"
      ],
      "metadata": {
        "id": "061d31siD5Gu",
        "outputId": "f8ad2869-1156-4b69-f685-b52fe4293226",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "ename": "AxisError",
          "evalue": "axis 1 is out of bounds for array of dimension 1",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-7474a45d287c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   1227\u001b[0m     \"\"\"\n\u001b[1;32m   1228\u001b[0m     \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'keepdims'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NoValue\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
          ]
        }
      ]
    }
  ]
}