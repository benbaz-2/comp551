{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "9Vm0VqmS9HT1"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMkxRZFmArD/ENTplxFD6Xq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benbaz-2/comp551/blob/main/CNN_task2.6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "b7BqROtrweV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install medmnist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syzqyYUqx36y",
        "outputId": "54756fea-d90d-4dc0-8e3b-28684212a7c1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting medmnist\n",
            "  Downloading medmnist-3.0.2-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from medmnist) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.5.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.24.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from medmnist) (4.66.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from medmnist) (11.0.0)\n",
            "Collecting fire (from medmnist)\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/87.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from medmnist) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.20.1+cu121)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->medmnist) (2.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (1.13.1)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (3.4.2)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2.36.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2024.9.20)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (4.12.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->medmnist) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->medmnist) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->medmnist) (3.0.2)\n",
            "Downloading medmnist-3.0.2-py3-none-any.whl (25 kB)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=6886bd7a236e00bb3f41ed97b5aaf86fc58d018bb82b4827628f08744adeb66a\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/39/2f/2d3cadc408a8804103f1c34ddd4b9f6a93497b11fa96fe738e\n",
            "Successfully built fire\n",
            "Installing collected packages: fire, medmnist\n",
            "Successfully installed fire-0.7.0 medmnist-3.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pIStVwXxtN0A"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from medmnist import OrganAMNIST\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import itertools\n",
        "from matplotlib import pyplot\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import MNIST, FashionMNIST\n",
        "from torchvision.transforms import ToTensor, Compose, Normalize, RandomHorizontalFlip, RandomRotation"
      ],
      "metadata": {
        "id": "rxOM4EiO2Boy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define transforms"
      ],
      "metadata": {
        "id": "9Vm0VqmS9HT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])"
      ],
      "metadata": {
        "id": "qr5g_L2Y9JKV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data"
      ],
      "metadata": {
        "id": "TjA1axWjxsrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = OrganAMNIST(split='train', download=True, transform=transform)\n",
        "test_dataset = OrganAMNIST(split='test', download=True, transform=transform)\n",
        "val_dataset = OrganAMNIST(split='val', download=True, transform=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgal990exwMc",
        "outputId": "e761bb2e-8319-4c89-f7f4-684723e70c04"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://zenodo.org/records/10519652/files/organamnist.npz?download=1 to /root/.medmnist/organamnist.npz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 38.2M/38.2M [00:03<00:00, 9.81MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using downloaded and verified file: /root/.medmnist/organamnist.npz\n",
            "Using downloaded and verified file: /root/.medmnist/organamnist.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use dataloaders\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "Vzdav7Wv9ic4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model implementation"
      ],
      "metadata": {
        "id": "R11uSCc7y-bu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_filters = 8\n",
        "filter_size = 3\n",
        "pool_size   = 2\n",
        "num_classes = 10\n",
        "batch_size  = 64\n",
        "strides     = 1\n",
        "padding     = 1  # Padding of 1 with filter size of 3 output the same dimension\n",
        "dropout_rate = 0.25\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential()\n",
        "        self.model.append(nn.Conv2d(1, num_filters, filter_size, strides, padding))\n",
        "\n",
        "        self.model.append(nn.MaxPool2d(pool_size))\n",
        "\n",
        "        self.model.append(nn.Conv2d(num_filters,  num_filters ** 2, filter_size, strides, padding))\n",
        "        self.model.append(nn.ReLU())\n",
        "        self.model.append(nn.MaxPool2d(pool_size))\n",
        "\n",
        "        self.model.append(nn.Dropout(dropout_rate)) # randomly sets input units to 0 with a frequency of rate at each step during training time, to avoid overfitting\n",
        "        self.model.append(nn.Flatten()) # Flatten serves as a connection between the convolution and dense layers\n",
        "        self.model.append(nn.Linear(3136, 1000)) # hidden layer\n",
        "        self.model.append(nn.ReLU())\n",
        "        self.model.append(nn.Dropout(dropout_rate))\n",
        "        self.model.append(nn.Linear(1000, num_classes))\n",
        "        self.model.append(nn.Softmax(dim=1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n"
      ],
      "metadata": {
        "id": "qM7vxReMy6Zt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "1khcoTDrDCDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "model = CNN()\n",
        "model.to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "num_epochs = 10"
      ],
      "metadata": {
        "id": "my58NRNBFlno"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_accuracy(model = model, data_loader = train_loader, device=device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculation for evaluation\n",
        "        for images, labels in data_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)  # Get logits\n",
        "            _, predicted = torch.max(outputs.data, 1)  # Get predicted class indices\n",
        "\n",
        "            total += labels.size(0)  # Total number of labels\n",
        "            correct += (predicted == labels).sum().item()  # Count correct predictions\n",
        "\n",
        "    accuracy = correct / total * 100  # Convert to percentage\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "nPIlf4LCHJVy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train(model=model, optimizer=optimizer, train_loader=train_loader, val_loader=val_loader, criterion=criterion, num_epochs=num_epochs, device=device):\n",
        "\n",
        "    # Training loop\n",
        "    history = {\"loss\": [], \"accuracy\": [], \"val_accuracy\": []}\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set the model to training mode\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for images, labels in tqdm(train_loader):\n",
        "            # Move tensors to the configured device (GPU or CPU)\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Print the average loss for the epoch\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
        "        history[\"loss\"].append(running_loss/len(train_loader))\n",
        "        history[\"accuracy\"].append(compute_accuracy(model, train_loader, device))\n",
        "        history[\"val_accuracy\"].append(compute_accuracy(model, test_loader, device))\n",
        "\n",
        "    print('Training complete!')\n",
        "    return history\n",
        "\n"
      ],
      "metadata": {
        "id": "LLFqr_vbDI_N"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = train()"
      ],
      "metadata": {
        "id": "GOi2r_hFFdMq",
        "outputId": "230f2e93-02d5-4f4b-c65e-9e3a9177f37c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!pip install medmnist\n",
            "import torch\n",
            "import torch.nn as nn\n",
            "import torch.optim as optim\n",
            "from torchvision import datasets, transforms\n",
            "from torch.utils.data import DataLoader\n",
            "import numpy as np\n",
            "import matplotlib.pyplot as plt\n",
            "from medmnist import OrganAMNIST\n",
            "from tqdm import tqdm\n",
            "import os\n",
            "import numpy as np\n",
            "import shutil\n",
            "import pandas as pd\n",
            "import matplotlib.pyplot as plt\n",
            "import seaborn as sns\n",
            "import itertools\n",
            "from matplotlib import pyplot\n",
            "import matplotlib.image as mpimg\n",
            "\n",
            "import torch\n",
            "import torch.nn as nn\n",
            "from torchvision.datasets import MNIST, FashionMNIST\n",
            "from torchvision.transforms import ToTensor, Compose, Normalize, RandomHorizontalFlip, RandomRotation\n",
            "transform = transforms.Compose([\n",
            "    transforms.ToTensor(),\n",
            "    transforms.Normalize((0.5,), (0.5,))\n",
            "])\n",
            "train_dataset = OrganAMNIST(split='train', download=True, transform=transform)\n",
            "test_dataset = OrganAMNIST(split='test', download=True, transform=transform)\n",
            "val_dataset = OrganAMNIST(split='val', download=True, transform=transform)\n",
            "# Use dataloaders\n",
            "batch_size = 64\n",
            "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
            "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
            "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
            "num_filters = 8\n",
            "filter_size = 3\n",
            "pool_size   = 2\n",
            "num_classes = 10\n",
            "batch_size  = 64\n",
            "strides     = 1\n",
            "padding     = 1  # Padding of 1 with filter size of 3 output the same dimension\n",
            "dropout_rate = 0.25\n",
            "\n",
            "class CNN(nn.Module):\n",
            "    def __init__(self):\n",
            "        super().__init__()\n",
            "        self.model = nn.Sequential()\n",
            "        self.model.append(nn.Conv2d(1, num_filters, filter_size, strides, padding))\n",
            "\n",
            "        self.model.append(nn.MaxPool2d(pool_size))\n",
            "\n",
            "        self.model.append(nn.Conv2d(num_filters,  num_filters ** 2, filter_size, strides, padding))\n",
            "        self.model.append(nn.ReLU())\n",
            "        self.model.append(nn.MaxPool2d(pool_size))\n",
            "\n",
            "        self.model.append(nn.Dropout(dropout_rate)) # randomly sets input units to 0 with a frequency of rate at each step during training time, to avoid overfitting\n",
            "        self.model.append(nn.Flatten()) # Flatten serves as a connection between the convolution and dense layers\n",
            "        self.model.append(nn.Linear(3136, 1000)) # hidden layer\n",
            "        self.model.append(nn.ReLU())\n",
            "        self.model.append(nn.Dropout(dropout_rate))\n",
            "        self.model.append(nn.Linear(1000, num_classes))\n",
            "        self.model.append(nn.Softmax(dim=1))\n",
            "\n",
            "    def forward(self, x):\n",
            "        return self.model(x)\n",
            "if torch.cuda.is_available():\n",
            "    device = torch.device(\"cuda\")\n",
            "else:\n",
            "    device = torch.device(\"cpu\")\n",
            "model = CNN()\n",
            "model.to(device)\n",
            "\n",
            "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
            "criterion = nn.CrossEntropyLoss()\n",
            "num_epochs = 10\n",
            "def compute_accuracy(model = model, data_loader = train_loader, device=device):\n",
            "    model.eval()  # Set the model to evaluation mode\n",
            "    correct = 0\n",
            "    total = 0\n",
            "\n",
            "    with torch.no_grad():  # Disable gradient calculation for evaluation\n",
            "        for images, labels in data_loader:\n",
            "            images, labels = images.to(device), labels.to(device)\n",
            "\n",
            "            # Forward pass\n",
            "            outputs = model(images)  # Get logits\n",
            "            _, predicted = torch.max(outputs.data, 1)  # Get predicted class indices\n",
            "\n",
            "            total += labels.size(0)  # Total number of labels\n",
            "            correct += (predicted == labels).sum().item()  # Count correct predictions\n",
            "\n",
            "    accuracy = correct / total * 100  # Convert to percentage\n",
            "    return accuracy\n",
            "\n",
            "def train(model=model, optimizer=optimizer, train_loader=train_loader, val_loader=val_loader, criterion=criterion, num_epochs=num_epochs, device=device):\n",
            "\n",
            "    # Training loop\n",
            "    history = {\"loss\": [], \"accuracy\": [], \"val_accuracy\": []}\n",
            "\n",
            "    for epoch in range(num_epochs):\n",
            "        model.train()  # Set the model to training mode\n",
            "        running_loss = 0.0\n",
            "\n",
            "        for images, labels in tqdm(train_loader):\n",
            "            # Move tensors to the configured device (GPU or CPU)\n",
            "            images, labels = images.to(device), labels.to(device)\n",
            "\n",
            "            # Zero the gradients\n",
            "            optimizer.zero_grad()\n",
            "\n",
            "            # Forward pass\n",
            "            outputs = model(images)\n",
            "\n",
            "            # Calculate loss\n",
            "            loss = criterion(outputs, labels)\n",
            "\n",
            "            # Backward pass and optimization\n",
            "            loss.backward()\n",
            "            optimizer.step()\n",
            "\n",
            "            running_loss += loss.item()\n",
            "\n",
            "        # Print the average loss for the epoch\n",
            "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
            "        history[\"loss\"].append(running_loss/len(train_loader))\n",
            "        history[\"accuracy\"].append(compute_accuracy(model, train_loader, device))\n",
            "        history[\"val_accuracy\"].append(compute_accuracy(model, test_loader, device))\n",
            "\n",
            "    print('Training complete!')\n",
            "    return history\n",
            "history\n"
          ]
        }
      ]
    }
  ]
}